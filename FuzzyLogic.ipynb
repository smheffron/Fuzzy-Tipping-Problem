{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def fuzzy_complement(ax):\n",
    "    return 1 - ax\n",
    "\n",
    "def fuzzy_union(ax, bx):\n",
    "    return max(ax, bx)\n",
    "\n",
    "def fuzzy_intersection(ax, bx):\n",
    "    return min(ax, bx)\n",
    "\n",
    "#used to take combine multiple antecedents\n",
    "def cylindrical_closure_of_antecedents(A, B):\n",
    "    aShape= A.shape\n",
    "    bShape= B.shape\n",
    "    \n",
    "    dim = len(bShape)\n",
    "      \n",
    "    #tried to make cases for dim... not sure if there is a better way to do it.\n",
    "    if(dim == 1):\n",
    "        cross_antecedents = np.zeros((aShape[0], bShape[0])) \n",
    "        \n",
    "        for i in range(aShape[0]):\n",
    "            for j in range(bShape[0]):\n",
    "                cross_antecedents[i][j] = min(A[i], B[j])\n",
    "        \n",
    "    if(dim == 2):\n",
    "        cross_antecedents = np.zeros((aShape[0], bShape[0], bShape[1]))\n",
    "        \n",
    "        for i in range(aShape[0]):\n",
    "            for j in range(bShape[0]):\n",
    "                for k in range(bShape[1]):\n",
    "                    cross_antecedents[i][j][k] = min(A[i], B[j][k])\n",
    "                \n",
    "    if(dim == 3):\n",
    "        cross_antecedents = np.zeros((aShape[0], bShape[0], bShape[1], bShape[2]))\n",
    "        \n",
    "        for i in range(aShape[0]):\n",
    "            for j in range(bShape[0]):\n",
    "                for k in range(bShape[1]):\n",
    "                    for l in range(bShape[2]):\n",
    "                        cross_antecedents[i][j][k][l] = min(A[i], B[j][k][l])\n",
    "                    \n",
    "    if(dim == 4):\n",
    "        cross_antecedents = np.zeros((aShape[0], bShape[0], bShape[1], bShape[2], bShape[3]))\n",
    "        \n",
    "        for i in range(aShape[0]):\n",
    "            for j in range(bShape[0]):\n",
    "                for k in range(bShape[1]):\n",
    "                    for l in range(bShape[2]):\n",
    "                        for m in range(bShape[3]):\n",
    "                            cross_antecedents[i][j][k][l][m] = min(A[i], B[j][k][l][m])\n",
    "                        \n",
    "    if(dim == 5):\n",
    "        cross_antecedents = np.zeros((aShape[0], bShape[0], bShape[1], bShape[2], bShape[3], bShape[4]))\n",
    "        \n",
    "        for i in range(aShape[0]):\n",
    "            for j in range(bShape[0]):\n",
    "                for k in range(bShape[1]):\n",
    "                    for l in range(bShape[2]):\n",
    "                        for m in range(bShape[3]):\n",
    "                            for n in range(bShape[4]):\n",
    "                                cross_antecedents[i][j][k][l][m][n] = min(A[i], B[j][k][l][m][n])\n",
    "                            \n",
    "    return cross_antecedents\n",
    "\n",
    "# The different imp. op.\n",
    "\n",
    "def lukasiewicz(x, y):\n",
    "    return min(1, (1-x)+y)\n",
    "\n",
    "def correlation_min(x, y):\n",
    "    return min(x, y)\n",
    "\n",
    "def correlation_product(x, y):\n",
    "    return (x*y)\n",
    "\n",
    "# implication_op\n",
    "# -> z = Lukasiewicz\n",
    "# -> cm = correlation min\n",
    "# -> cp = correlation product\n",
    "\n",
    "#builds the fuzzy relation between the propositions and the consequent for the spec. imp. op. \n",
    "def build_fuzzy_relation(A, B, implication_op):\n",
    "    aShape= A.shape\n",
    "    bShape= B.shape\n",
    "        \n",
    "    dim = len(bShape)\n",
    "        \n",
    "    if(dim == 1):\n",
    "        cross_antecedents = np.zeros((aShape[0], bShape[0])) \n",
    "        \n",
    "        for i in range(aShape[0]):\n",
    "            for j in range(bShape[0]):\n",
    "                if(implication_op == \"cm\"):\n",
    "                    cross_antecedents[i][j] = correlation_min(A[i], B[j])\n",
    "                if(implication_op == \"cp\"):\n",
    "                    cross_antecedents[i][j] = correlation_product(A[i], B[j])\n",
    "                if(implication_op == \"z\"):\n",
    "                    cross_antecedents[i][j] = lukasiewicz(A[i], B[j])\n",
    "        \n",
    "    if(dim == 2):\n",
    "        cross_antecedents = np.zeros(( aShape[0], bShape[0], bShape[1] ))\n",
    "        \n",
    "        for i in range(aShape[0]):\n",
    "            for j in range(bShape[0]):\n",
    "                for k in range(bShape[1]):\n",
    "                    if(implication_op == \"cm\"):\n",
    "                        cross_antecedents[i][j][k] = correlation_min(A[i], B[j][k])\n",
    "                    if(implication_op == \"cp\"):\n",
    "                        cross_antecedents[i][j][k] = correlation_product(A[i], B[j][k])\n",
    "                    if(implication_op == \"z\"):\n",
    "                        cross_antecedents[i][j][k] = lukasiewicz(A[i], B[j][k])\n",
    "                \n",
    "    if(dim == 3):\n",
    "        cross_antecedents = np.zeros((aShape[0], bShape[0], bShape[1], bShape[2]))\n",
    "        \n",
    "        for i in range(aShape[0]):\n",
    "            for j in range(bShape[0]):\n",
    "                for k in range(bShape[1]):\n",
    "                    for l in range(bShape[2]):\n",
    "                        if(implication_op == \"cm\"):\n",
    "                            cross_antecedents[i][j][k][l] = correlation_min(A[i], B[j])\n",
    "                        if(implication_op == \"cp\"):\n",
    "                            cross_antecedents[i][j][k][l] = correlation_product(A[i], B[j])\n",
    "                        if(implication_op == \"z\"):\n",
    "                            cross_antecedents[i][j][k][l] = lukasiewicz(A[i], B[j])\n",
    "                    \n",
    "    if(dim == 4):\n",
    "        cross_antecedents = np.zeros((aShape[0], bShape[0], bShape[1], bShape[2], bShape[3]))\n",
    "        \n",
    "        for i in range(aShape[0]):\n",
    "            for j in range(bShape[0]):\n",
    "                for k in range(bShape[1]):\n",
    "                    for l in range(bShape[2]):\n",
    "                        for m in range(bShape[3]):\n",
    "                            if(implication_op == \"cm\"):\n",
    "                                cross_antecedents[i][j][k][l][m] = correlation_min(A[i], B[j])\n",
    "                            if(implication_op == \"cp\"):\n",
    "                                cross_antecedents[i][j][k][l][m] = correlation_product(A[i], B[j])\n",
    "                            if(implication_op == \"z\"):\n",
    "                                cross_antecedents[i][j][k][l][m] = lukasiewicz(A[i], B[j])\n",
    "                        \n",
    "    if(dim == 5):\n",
    "        cross_antecedents = np.zeros((aShape[0], bShape[0], bShape[1], bShape[2], bShape[3], bShape[4]))\n",
    "        \n",
    "        for i in range(aShape[0]):\n",
    "            for j in range(bShape[0]):\n",
    "                for k in range(bShape[1]):\n",
    "                    for l in range(bShape[2]):\n",
    "                        for m in range(bShape[3]):\n",
    "                            for n in range(bShape[4]):\n",
    "                                if(implication_op == \"cm\"):\n",
    "                                    cross_antecedents[i][j][k][l][m][n] = correlation_min(A[i], B[j])\n",
    "                                if(implication_op == \"cp\"):\n",
    "                                    cross_antecedents[i][j][k][l][m][n] = correlation_product(A[i], B[j])\n",
    "                                if(implication_op == \"z\"):\n",
    "                                    cross_antecedents[i][j][k][l][m][n] = lukasiewicz(A[i], B[j])\n",
    "                            \n",
    "    return cross_antecedents\n",
    "\n",
    "#generalized modus ponenens\n",
    "def compositional_rule_of_inference(Aprime, rule_matrix):\n",
    "    shape = rule_matrix.shape\n",
    "        \n",
    "    Bprime = np.zeros((shape[1],1))\n",
    "    mins = np.zeros((shape[0],1))\n",
    "    \n",
    "    dim = len(shape)\n",
    "    if(dim == 2):        \n",
    "        for j in range(shape[1]):\n",
    "            for k in range(shape[0]):\n",
    "                mins[k] = min(rule_matrix[k][j], Aprime[k])\n",
    "            Bprime[j] = np.amax(mins)\n",
    "            mins = np.zeros((shape[0],1))\n",
    "    return Bprime\n",
    "\n",
    "#take the center of mass to get a crisp value out of the resulting FS\n",
    "def centroid_deffuzification(bPrime):\n",
    "    shape = bPrime.shape\n",
    "    top = 0.0\n",
    "    bottom = 0.0\n",
    "    \n",
    "    for i in range (bPrime.shape[0]):\n",
    "        top += (1+i)*bPrime[i]\n",
    "        bottom += bPrime[i]\n",
    "    \n",
    "    return (top/bottom)\n",
    "\n",
    "#Used for real-valued calc. to get membership value of input\n",
    "def fire_antecendent(x, membership_fn):\n",
    "    x = int(x)\n",
    "    return membership_fn[x]\n",
    "\n",
    "#used for float inputs\n",
    "def fire_antecendent_by1(x, membership_fn):\n",
    "    x = int(x*10)\n",
    "    return membership_fn[x]\n",
    "\n",
    "#used to determine where to \"chop\" the consequent\n",
    "def get_min_firing_strength(antecedent_strengths):\n",
    "    return np.amin(antecedent_strengths)\n",
    "\n",
    "#chop consequent based on min. fire strength of all antecedents\n",
    "def chop_consequent(implication_op, min_firing_strength, consequent_membership_fn):\n",
    "    res = np.zeros((consequent_membership_fn.shape))\n",
    "        \n",
    "    for i in range(consequent_membership_fn.shape[0]):\n",
    "        if(implication_op == \"cm\"):\n",
    "            res[i] = correlation_min(min_firing_strength, consequent_membership_fn[i])\n",
    "        if(implication_op == \"cp\"):\n",
    "            res[i] = correlation_product(min_firing_strength, consequent_membership_fn[i])\n",
    "        if(implication_op == \"z\"):\n",
    "            res[i] = lukasiewicz(min_firing_strength, consequent_membership_fn[i])\n",
    "            \n",
    "    return res\n",
    "\n",
    "#aggregate the consequents using SUM\n",
    "def aggregate_chopped_consequents(chopped_consequents):\n",
    "    res = np.zeros((chopped_consequents.shape[1]))\n",
    "    s=0\n",
    "    \n",
    "    for i in range(chopped_consequents.shape[1]):\n",
    "        for j in range(chopped_consequents.shape[0]):\n",
    "            s += chopped_consequents[j][i]\n",
    "        res[i] = s\n",
    "        s = 0\n",
    "        \n",
    "    return res\n",
    "\n",
    "#take the MAX of all chopped conseqeuts, used in the classification\n",
    "def aggregate_chopped_consequents_i(chopped_consequents):    \n",
    "    res = np.zeros((chopped_consequents.shape[1]))\n",
    "    \n",
    "    temp = 0\n",
    "    \n",
    "    maxs = np.zeros((chopped_consequents.shape[0]))\n",
    "    \n",
    "    for i in range(chopped_consequents.shape[0]):\n",
    "        for j in range(chopped_consequents.shape[1]):\n",
    "            temp = temp + chopped_consequents[i][j]\n",
    "        maxs[i] = temp\n",
    "        temp = 0\n",
    "\n",
    "    i = np.argmax(maxs)\n",
    "        \n",
    "    return i\n",
    "\n",
    "#generalized trap. membership makers, ints only\n",
    "def make_trap_membership_fn(X, a, b, c, d):\n",
    "    Y = np.zeros((X.shape))\n",
    "    \n",
    "    for i in range(a):\n",
    "        Y[i] = 0\n",
    "    for i in range(a,b):\n",
    "        Y[i] = (i-a)/(b-a)\n",
    "    for i in range(b,c):\n",
    "        Y[i] = 1\n",
    "    for i in range(c,d):\n",
    "        Y[i] = (d-i)/(d-c)\n",
    "    for i in range(d,X.shape[0]):\n",
    "        Y[i] = 0\n",
    "        \n",
    "#     plt.plot(Y)\n",
    "#     plt.ylabel('membership value')\n",
    "#     plt.xticks(np.arange(len(Y)), np.arange(1, len(Y)+1))\n",
    "#     plt.xlabel(\"rating\")\n",
    "#     plt.show()\n",
    "    \n",
    "    return Y\n",
    "\n",
    "#makes a trap for float inputs\n",
    "def make_trap_membership_fn_float(X, a, b, c, d):\n",
    "    Y = np.zeros((X.shape))\n",
    "    \n",
    "    a = int(10*a)\n",
    "    b = int(10*b)\n",
    "    c = int(10*c)\n",
    "    d = int(10*d)\n",
    "    \n",
    "    for i in range(a):\n",
    "        Y[i] = 0\n",
    "    for i in range(a,b):\n",
    "        Y[i] = (i-a)/(b-a)\n",
    "    for i in range(b,c):\n",
    "        Y[i] = 1\n",
    "    for i in range(c,d):\n",
    "        Y[i] = (d-i)/(d-c)\n",
    "    for i in range(d,X.shape[0]):\n",
    "        Y[i] = 0\n",
    "        \n",
    "#     plt.plot(Y)\n",
    "#     plt.ylabel('membership value')\n",
    "#     plt.xticks(np.arange(len(Y), step=10), [\"0.0\", \"1.0\", \"2.0\", \"3.0\", \"4.0\", \"5.0\", \"6.0\", \"7.0\", \"8.0\", \"9.0\"])\n",
    "#     plt.show()\n",
    "    \n",
    "    return Y\n",
    "\n",
    "#graphical rep.\n",
    "def print_chopped_consequents(cc, agr):\n",
    "    \n",
    "    for i in range(cc.shape[0]):\n",
    "        plt.plot(cc[i], label=('Consequent ',i))\n",
    "    plt.plot(agr, label=\"Aggregated Consequents\")\n",
    "    plt.ylabel('membership value')\n",
    "    plt.yticks(np.arange(0, 1.2, step=0.2))\n",
    "    plt.xticks(np.arange(cc.shape[1]), np.arange(1, cc.shape[1]+1))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "#class for a rule, contains the ant. conseq indices\n",
    "class Rule:\n",
    "    def __init__(self, a, c):\n",
    "        self.antecedents = a\n",
    "        self.consqeunt = np.array(c)\n",
    "    \n",
    "# the 'main' function, starts it all\n",
    "def generalized_fuzzy_logic(rules, antecedent_membership_fns, consequent_membership_fns, implication_op, inputs):\n",
    "    num_input = inputs.shape[0]\n",
    "    num_cmembership_fns = len(consequent_membership_fns)\n",
    "    num_amembership_fns = len(antecedent_membership_fns)\n",
    "    num_rules = len(rules)\n",
    "    num_inputs = len(inputs)\n",
    "    \n",
    "    choppedConseq = []\n",
    "    \n",
    "    cc = np.zeros((num_rules, consequent_membership_fns[0].shape[0]))\n",
    "    \n",
    "    for i in range(num_rules):\n",
    "        mins = np.zeros(rules[i].antecedents.shape[0])\n",
    "        for j in range(rules[i].antecedents.shape[0]):\n",
    "            mins[j] = fire_antecendent(inputs[j], antecedent_membership_fns[int(rules[i].antecedents[j])])\n",
    "        minf = get_min_firing_strength(mins)\n",
    "        choppedConseq.append(chop_consequent(implication_op, minf, consequent_membership_fns[int(rules[i].consqeunt)]))\n",
    "        \n",
    "    for i in range(num_rules):\n",
    "        for j in range(cc.shape[1]):\n",
    "            cc[i][j] = choppedConseq[i][j]\n",
    "    \n",
    "    res = aggregate_chopped_consequents(cc)\n",
    "    \n",
    "    res= normalize_con(res)\n",
    "    \n",
    "#     print_chopped_consequents(cc, res)\n",
    "    \n",
    "    return res\n",
    "\n",
    "#used for float inputs (like the classification)\n",
    "def generalized_fuzzy_logic_f(rules, antecedent_membership_fns, consequent_membership_fns, implication_op, inputs):\n",
    "    num_input = inputs.shape[0]\n",
    "    num_cmembership_fns = len(consequent_membership_fns)\n",
    "    num_amembership_fns = len(antecedent_membership_fns)\n",
    "    num_rules = len(rules)\n",
    "    num_inputs = len(inputs)\n",
    "    \n",
    "    choppedConseq = []\n",
    "    \n",
    "    cc = np.zeros((num_rules, consequent_membership_fns[0].shape[0]))\n",
    "    \n",
    "    for i in range(num_rules):\n",
    "        mins = np.zeros(rules[i].antecedents.shape[0])\n",
    "        for j in range(rules[i].antecedents.shape[0]):\n",
    "            mins[j] = fire_antecendent_by1(inputs[j], antecedent_membership_fns[int(rules[i].antecedents[j])])\n",
    "        minf = get_min_firing_strength(mins)\n",
    "        choppedConseq.append(chop_consequent(implication_op, minf, consequent_membership_fns[int(rules[i].consqeunt)]))\n",
    "        \n",
    "    for i in range(num_rules):\n",
    "        for j in range(cc.shape[1]):\n",
    "            cc[i][j] = choppedConseq[i][j]\n",
    "    \n",
    "    res = aggregate_chopped_consequents_i(cc)\n",
    "    \n",
    "#     print_chopped_consequents(cc, res)\n",
    "            \n",
    "    return res\n",
    "\n",
    "# graphical rep.\n",
    "def print_normalized_aggr(res, center):\n",
    "    plt.plot(res, label=\"Aggregated Consequents\")\n",
    "    plt.ylabel('membership value')\n",
    "    plt.xticks(np.arange(res.shape[0]), np.arange(1, res.shape[0]+1))\n",
    "    plt.axvline(x=center-1, color=\"red\")\n",
    "    plt.text(13, 0, 'TIP')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "#may need to normalize if added conseq. exceed one\n",
    "def normalize_con(B):\n",
    "    minB = np.amin(B)\n",
    "    maxB = np.amax(B)\n",
    "    \n",
    "    for i in range(B.shape[0]):\n",
    "        top = (B[i] - minB)\n",
    "        bottom = (maxB - minB)\n",
    "        if(bottom == 0):\n",
    "            B[i] = 0\n",
    "        else:\n",
    "            B[i] = top/bottom\n",
    "            \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
